---
title: "p8105_hw5_yz4993"
author: "Yixin Zheng"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
library(broom)
library(readr)
library(purrr)
```

#Problem 1
```{r p1_create function}
simulate_birthday <- function(n) {
  birthdays <- sample(1:365, n, replace = TRUE) # assign random birthdays
  any(duplicated(birthdays)) # check for duplicate birthdays
  }
```

```{r p1_parameters}
set.seed(42)
sizes <- 2:50
num_of_times_1 <- 10000
```

```{r p1_simulation}
p1_results <- tibble(
  group_size = sizes,
  probability = map_dbl(sizes, 
                        function(n) {
                          mean(replicate(num_of_times_1,
                                         simulate_birthday(n)))
                          })
  )

# another method:
# sim_results_df <- expand_grid(group_size = 2:50, iter = 1:10000) |> mutate(has_shared_birthday = map_lgl(group_size, simulate_birthday)) |> group_by(group_size) |> summarize(probability = mean(has_shared_birthday), .groups = "drop")
```

```{r p1_plot}
p1_results %>%
  ggplot(aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthday in a Group",
    x = "Number of People in Group",
    y = "Probability"
    ) +
  theme_minimal(base_size = 14)
```

The plot above shows that as the group size increases, the probability of that at least two people in the group will share a birthday also increase. Around group size of 23,the probability exceeds 0.5(50%), and in group of 50 people, the probability is very close to 1(100%). Meaning

# Problem 2
```{r p2_parameter}
n <- 30
sigma <- 5
num_of_times_2 <- 5000
mu_values <- c(1, 2, 3, 4, 5, 6)
```

```{r p2_function}
t_test <- function(mu) {
  x <- rnorm(n, mean = mu, sd = sigma)
  t_test_result <- t.test(x, mu = 0)
  tidy(t_test_result) %>% 
    select(estimate, p.value)
}
```

```{r p2_mu0 simulation}
set.seed(42)
mu0_results <- tibble(
  iter = 1:num_of_times_2,
  test_result = map(iter, ~ t_test(mu = 0))
  ) %>%
  unnest(test_result)
```

```{r p2_mu0 power}
mu0_power <- mean(mu0_results$p.value < 0.05)
mu0_power
```


```{r p2_mu_values simulation}
mu_value_results <- expand_grid(
  mu = mu_values,
  iter = 1:num_of_times_2
  ) %>%
  mutate(
    test_result = map(mu, ~ t_test(.x))
    ) %>%
  unnest(test_result)
```

```{r p2_mu_values power}
mu_values_power <- mu_value_results %>%
  group_by(mu) %>%
  summarize(power = mean(p.value < 0.05), 
            .groups = "drop")
mu_values_power

# combine mu = 0 result with other power results
power_results <- bind_rows(
  tibble(mu = 0, power = mu0_power),
  mu_values_power
)
power_results
```

```{r p2_power plot}
power_plot <- power_results %>%
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of the Test vs. True Value of mu",
    x = "True Value of mu",
    y = "Power"
  ) +
  theme_minimal(base_size = 14)
power_plot
```
The plot above shows a positive association between effect size and the power of the test. As the true value of mu increases, the power of the test also increases.

```{r p2_average estimate}
avg_estimates <- mu_value_results %>%
  group_by(mu) %>%
  summarize(
    avg_mu_hat_alltest = mean(estimate),
    avg_mu_hat_rejected = mean(estimate[p.value < 0.05]),
    .groups = "drop"
  )

avg_mu_0 <- tibble(
  mu = 0,
  avg_mu_hat_alltest = mean(mu0_results$estimate),
  avg_mu_hat_rejected = mean(mu0_results$estimate[mu0_results$p.value < 0.05])
)

avg_estimates <- bind_rows(avg_mu_0, avg_estimates)
```

```{r p2_estimate plot}
estimate_plot <- avg_estimates %>%
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat_alltest, color = "All Tests")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Rejected Nulls")) +
  geom_point(aes(y = avg_mu_hat_alltest, color = "All Tests")) +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Rejected Nulls")) +
  labs(
    title = "Average Estimate of hat(Mu) by True Values of Mu",
    x = "True Values of Mu",
    y = "Average Estimate of hat(Mu)",
    color = "Group"
  ) +
  theme_minimal(base_size = 14)

estimate_plot
```

The sample average of hat(mu) across tests for which the null is rejected is not approximately equal to the true value of mu, especially at lower values of mu but it becomes closer as mu increases.
Because when we are only considering hat(mu) in samples for which the null was rejected, it will be more likely to include tests with estimates of larger effect because that would pass the alpha = 0.05, and thus would tend to results in a slight overestimate in smaller values of the true mean, but the we will have better approximation at larger values.

# Problem 3
```{r p3_load data}
file_path <- "~/Desktop/Data Science/HW/HW5/p8105_hw5_yz4993/data/homicide-data.csv"
homicide_data <- read_csv(file_path)
```

The Washington Post homicide dataset has 52,179 records with 12 variables, showcasing homicides in 50 U.S. cities. This dataset includes victim demographics such as race, age, sex and case status + information such as uid and reported date, and location information such as latitude, longitude, city and state. 

```{r p3_create variable}
homicide_summary <- homicide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% 
                               c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  )
```

```{r p3_baltimore prop.test}
balMD_data <- homicide_summary %>%
  filter(city_state == "Baltimore, MD")

balMD_test <- prop.test(
  x = balMD_data$unsolved_homicides,
  n = balMD_data$total_homicides
)

balMD_summary <- broom::tidy(balMD_test) %>%
  select(estimate, conf.low, conf.high)
balMD_summary
```

```{r p3_each city}
prop_test <- function(unsolved, total) {
  if (total < 10) { 
    prop_test_result <- binom.test(x = unsolved, n = total)
    broom::tidy(prop_test_result) %>%
      select(estimate, conf.low, conf.high)
  } else {
    prop_test_result <- prop.test(x = unsolved, n = total)
    broom::tidy(prop_test_result) %>%
      select(estimate, conf.low, conf.high)
  }
}

city_estimates <- homicide_summary %>%
  mutate(
    test_results = map2(unsolved_homicides, total_homicides, prop_test)
  ) %>%
  unnest(test_results)

city_estimates
```

```{r p3_plot}
city_estimates %>%
  arrange(estimate) %>%
  mutate(city_state = factor(city_state, levels = unique(city_state))) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal()
```